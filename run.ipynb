{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logmmse\n",
    "import wave\n",
    "import logging\n",
    "\n",
    "import sox\n",
    "numba_logger = logging.getLogger('numba')\n",
    "numba_logger.setLevel(logging.WARNING)\n",
    "\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import commons\n",
    "import utils\n",
    "from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text.cleaners import japanese_cleaners2\n",
    "from text import cleaned_text_to_sequence\n",
    "from pypinyin import lazy_pinyin, Style\n",
    "import os\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def get_text(text, hps):\n",
    "    text_norm = cleaned_text_to_sequence(text)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm\n",
    "\n",
    "\n",
    "# hps_ms = utils.get_hparams_from_file(\"./configs/vctk_base.json\")\n",
    "# hps = utils.get_hparams_from_file(\"./configs/rmzk_base.json\")\n",
    "hps = utils.get_hparams_from_file(\"./configs/mmj.json\")\n",
    "# net_g_ms = SynthesizerTrn(\n",
    "#     len(symbols),\n",
    "#     hps_ms.data.filter_length // 2 + 1,\n",
    "#     hps_ms.train.segment_size // hps.data.hop_length,\n",
    "#     n_speakers=hps_ms.data.n_speakers,\n",
    "#     **hps_ms.model)\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    **hps.model)\n",
    "_ = net_g.eval()\n",
    "\n",
    "net_g_ms = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model)\n",
    "_ = net_g_ms.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tts(text):\n",
    "    stn_tst = get_text(text, hps)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)])\n",
    "        audio = net_g.infer(x_tst, x_tst_lengths, noise_scale=.667, noise_scale_w=0.8, length_scale=1)[0][\n",
    "            0, 0].data.float().numpy()\n",
    "        filename = 'file/out1.wav'\n",
    "        write(filename, 22050, audio)\n",
    "    ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate))\n",
    "\n",
    "\n",
    "def jtts(text,length_scale):\n",
    "\n",
    "    # tokenization\n",
    "    stn_tst = get_text(japanese_cleaners2(text), hps)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)])\n",
    "        audio = net_g.infer(x_tst, x_tst_lengths, noise_scale=.667, noise_scale_w=0.8, length_scale=length_scale)[0][\n",
    "            0, 0].data.float().numpy()\n",
    "        filename = 'resultwav/' +  text.replace('?','') + '.wav'\n",
    "        sf.write(filename,  audio,22050)\n",
    "    ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate))\n",
    "\n",
    "\n",
    "    # path = 'resultwav/' + text + '.wav'\n",
    "    # f = wave.open(path, \"r\")\n",
    "    # params = f.getparams()\n",
    "    # nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "    # print(\"nchannels:\", nchannels, \"sampwidth:\", sampwidth, \"framerate:\", framerate, \"nframes:\", nframes)\n",
    "    # data = f.readframes(nframes)\n",
    "    # f.close()\n",
    "    # data = np.fromstring(data, dtype=np.short)\n",
    "    #\n",
    "    # # 降噪\n",
    "    # data = logmmse.logmmse(data=data, sampling_rate=framerate)\n",
    "    # # 保存音频\n",
    "    # file_save = 'resultwav/' +'降噪_'+ text + '.wav'\n",
    "    # nframes = len(data)\n",
    "    # f = wave.open(file_save, 'w')\n",
    "    # f.setparams((1, 2, framerate, nframes, 'NONE', 'NONE'))  # 声道，字节数，采样频率，*，*\n",
    "    # # print(data)\n",
    "    # f.writeframes(data)  # outData\n",
    "    # f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint 'models/G_8000.pth' (iteration 21)\n"
     ]
    }
   ],
   "source": [
    "_ = utils.load_checkpoint(\"models/G_8000.pth\", net_g, None)\n",
    "# _ = utils.load_checkpoint(\"v_mzk/G_78000.pth\", net_g, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def multi_tts(text,speaker_id):\n",
    "    # speaker_id = \"0\" #@param [0, 1, 2, 3, 4]\n",
    "    speaker_id = int(speaker_id)\n",
    "    length_scale = 1.1 #@param {type:\"slider\", min:0.1, max:3, step:0.05}\n",
    "    sid = torch.LongTensor([speaker_id])\n",
    "    stn_tst = get_text(text, hps)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)])\n",
    "        audio = net_g_ms.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=length_scale)[0][0,0].data.float().numpy()\n",
    "    ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.Audio object>",
      "text/html": "\n                <audio  controls=\"controls\" >\n                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n                    Your browser does not support the audio element.\n                </audio>\n              "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_tts(\"そうと決まれば\" ,0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}